<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Effectivecamera | 稀有猿诉]]></title>
  <link href="http://toughcoder.net/blog/categories/effectivecamera/atom.xml" rel="self"/>
  <link href="http://toughcoder.net/"/>
  <updated>2023-05-16T21:36:30+08:00</updated>
  <id>http://toughcoder.net/</id>
  <author>
    <name><![CDATA[Alex Hilton]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Camera 2 API学习之小结]]></title>
    <link href="http://toughcoder.net/blog/2022/05/08/summary-of-camera-2-api-project/"/>
    <updated>2022-05-08T15:59:15+08:00</updated>
    <id>http://toughcoder.net/blog/2022/05/08/summary-of-camera-2-api-project</id>
    <content type="html"><![CDATA[<p>通过前面的<a href="http://toughcoder.net/blog/2022/04/24/camera-2-handling-3a-parameters/">一系列文章</a>，到现在已经算是学完了Camera 2 API的使用了，也做出一个具体基础功能的相机应用，目前可称得上是一个1.0版本了，后续会在此基础上进行迭代。本篇先进行一个小结。</p>

<p><a href=""><img src="https://tse1-mm.cn.bing.net/th/id/R-C.21389bf92d6ddcd68a53cbcf118eb665?rik=D%2f7xkH%2b7FC115w&amp;riu=http%3a%2f%2ffindnerd.s3.amazonaws.com%2fimagedata%2f8364%2f8364.jpg&amp;ehk=K55%2fBz%2favKGvIksdqHHaPCN3z%2bIIaDp9xclEICTNIOc%3d&amp;risl=&amp;pid=ImgRaw&amp;r=0" title="auto auto" ></a></p>

<script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>


<script>mermaid.initialize({startOnLoad:true});</script>




<!-- more -->


<h2>整体架构</h2>

<p><a href="http://toughcoder.net/blog/2022/05/06/camera-2-record-video/">上一篇文章</a>加入了录像模式，让整体复杂度又提升了一个层次，需要做一次业务逻辑抽离。前面一直使用CameraContext作为整体外部调用的接口，一部分业务逻辑，如启动预览，打开相机，关闭相机，和拍照都放在了CameraContext之中。现在因为多了录像模式，且涉及模式切换，如果仍都把逻辑放入到CameraContext之中，会非常的混乱，于是需要引入新的组件：</p>

<div class="mermaid">
classDiagram
CameraScene <|-- BaseScene
BaseScene <|-- PhotoScene
BaseScene <|-- VideoScene
PhotoOutputConfig -&#45;|&gt; OutputConfig
VideoOutputConfig -&#45;|&gt; OutputConfig
PhotoScene *-- PhotoOutputConfig
VideoScene *-- VideoOutputConfig
BaseScene <-- CameraContext
BaseScene *-- CameraAgent
CameraContext <-- CameraAgent
class CameraScene {
    &lt;&lt;interface&gt;&gt;
    attachCameraContext(CameraContext cameraContext)
    attachSaveAgent(PhotoSaveAgent saveAgent)
    activate()
    onResume()
    onPause()
    deactivate()
    clickShutter(Consumer~PhotoCaptureStatus~ consumer)
    updatePreviewSurface(Surface surface)
    setFlashMode(FlashMode flashMode)
    changeOutputConfig(OutputConfig config)
    switchCamera(Config.CameraFacing facing)
    addPreviewSizeListener(Consumer~CameraSize~ consumer)
    addStatusListener(Consumer~SceneStatus~ consumer)
    getSupportedFlashModes() List~FlashMode~
    FlashMode getFlashMode()
    getSupportedOutputConfigs() List~OutputConfig~
    getOutputConfig() OutputConfig
}
class BaseScene {
    Context context
    CameraContext.CameraThreadHandler cameraHandler
    List~Consumer~CameraSize~~ previewSizeListeners
    List~Consumer~SceneStatus~~ moduleStatusListeners
    List~FlashMode~ supportedFlashModes

    CameraContext cameraContext
    CameraAgent cameraAgent
    Surface previewSurface
    PhotoSaveAgent saveAgent
    FlashMode flashMode
    
    notifyStatus(SceneStatus status)
    notifyPreviewSize(CameraSize size)
    generateOutputTargets() List~Surface~
    checkCameraContext()
    onCameraAvailable()
}
class VideoScene {
    Surface recorderSurface
    MediaRecorder mediaRecorder
    File emptyFile
    List~VideoOutputConfig~ supportedOutputConfigs
    VideoOutputConfig currentOutputConfig
}
class PhotoScene {
    Optional~OrientationEventListener~ orientationEventListener
    int deviceOrientation
    List~PhotoOutputConfig~ supportedOutputConfigs
    PhotoOutputConfig currentOutputConfig
}
class OutputConfig {
    int id
    String displayName
    Config.PictureRatio ratio
}
class PhotoOutputConfig {
    int width
    int height
    int format
}
class VideoOutputConfig {
    int width
    int height
    int fps
}
class CameraContext {
   Context context
    CameraManagerWrapper cameraManager
    Map~Config.CameraFacing, CameraAgent~ cameraCache
    HandlerThread cameraManageThread
    CameraThreadHandler cameraThreadHandler
    CameraAgent currentCamera
    
    attachThread()
    detachThread()
    openCamera()
    closeCamera()
    createScene()
    getCurrentCamera() CameraAgent
}
class CameraAgent {
    CameraCharacteristics characteristics
    Optional~CameraDevice~ cameraDevice
    Optional~CameraCaptureSession~ captureSession
    PreviewCaptureCallback previewCallback
    CaptureRequest.Builder requestBuilder
    CameraParameters parameters
    
    calculateSupportedRatios() List~PhotoOutputConfig~
    getFlashModes() List~FlashMode~
    calculateVideoRecordMode() List~VideoOutputConfig~
    connect()
    disconnect()
    startPreview(List~Surface~)
    stopPreview()
    capturePhoto()
    setFlashMode(FlashMode mode)
}
</div>


<h3>CameraScene和BaseScene</h3>

<p>一个Scene可以定义为一个典型的用户使用场景，比如拍照场景和录像场景，场景是业务逻辑的主要实现者，它的前面是UI层，后面则是平台API封装层。</p>

<h3>VideoScene和PhotoScene</h3>

<p>目前为止两个使用场景，PhotoScenne负责拍照，从UI处接收命令，完成拍照；VideoScene则负责录像。</p>

<p><a href="https://postimg.cc/c6pwmfHj"><img src="https://i.postimg.cc/4NdPX5TJ/camera2.png" alt="camera2.png" /></a></p>

<h3>与CameraContext的关系</h3>

<p>现在CameraContext则是一个纯的线程管理和camera open/close管理，除此之外的其他逻辑全部都挪到了Scene中去。Scene与Context的关系是组合关系，Scene的所有操作都应该只发生在CameraContext的线程中。</p>

<h2>线程模型</h2>

<p>三个长驻线程，一个是主线程负责UI交互，一个是CameraContext线程，负责所有的业务逻辑，还有一个是存储，一旦结果出来了后余下的所有事情都在存储线程中。</p>

<div class="mermaid">
sequenceDiagram
    MainThread-&gt;>CameraManageThread: startPreview
    CameraManageThread-&#45;&gt;>MainThread: onPreviewSize
    MainThread->>CameraManageThread: capturePhoto
    CameraManageThread-&#45;&gt;>MainThread: captureStatus
    CameraManageThread-) ImageSaveThread: onCaptureComplete
    ImageSaveThread-&#45;&gt;>MainThread: onThumbnailArrive
</div>


<h2>组件通信</h2>

<p>通过接口进行隔离，均不产生强依赖关系。因为数据 都不复杂，所以用Consumer就可以了，具体的状态根据不同的场景定义一些enum即可。</p>

<h3>camera状态反馈</h3>

<p>用于隔离Scene和CameraAgent，反馈camera的连接状态，方便做一些与camera强相关的业务处理，比如一些事情（预览和拍照）只能是在camera处于连接状态才能做的事。</p>

<pre><code class="java">    cameraContext.openCamera(Config.currentFacing, status -&gt; {
            onCameraAvailable();
            notifyStatus(SceneStatus.ACTIVE);
        });
</code></pre>

<h3>Scene状态反馈</h3>

<p>隔离UI和CameraScene，UI的状态，如一些按扭的可点态和显示与隐藏，以及一些显示内容需要知道CameraScene的状态，当CameraScene处于ACTIVE状态时UI才会完全处于可用态。</p>

<pre><code class="java">    private Consumer&lt;SceneStatus&gt; moduleStatusListener = status -&gt; mainHandler.post(
            () -&gt; {
                statusView.setText(status.toString());
                if (status == SceneStatus.ACTIVE) {
                    onSceneActive();
                } else {
                    onSceneInactive();
                }
            }
    );
</code></pre>

<h3>预览尺寸变化 反馈</h3>

<p>比较纯，就是用于控制Surface的显示，它需要反馈当前预览的尺寸和比例。</p>

<pre><code class="java">    private Consumer&lt;CameraSize&gt; previewSizeListener = size -&gt; mainHandler.post(
            () -&gt; viewFinder.setAspectRatio(size.height, size.width)
    );
</code></pre>

<h3>拍照状态反馈</h3>

<p>这个仅在拍照时才需要。</p>

<pre><code class="java">    private final Consumer&lt;PhotoCaptureStatus&gt; captureStatusListener = status -&gt; {
        Log.d(LOG_TAG, "capture status " + status);
        statusView.setText("Capture Status: " + status);
        if (status == PhotoCaptureStatus.STARTED) {
            overlayView.setBackground(new ColorDrawable(Color.argb(150, 255, 255, 255)));
            mainHandler.postDelayed(() -&gt; overlayView.setBackground(null), Config.CAPTURE_ANIM_DURATION);
        } else if (status == PhotoCaptureStatus.COMPLETED) {
            shutterView.setClickable(true);
            cameraSwitchView.setClickable(true);
        } else if (status == PhotoCaptureStatus.FAILED) {
            thumbnailSwitcher.setClickable(true);
            shutterView.setClickable(true);
            cameraSwitchView.setClickable(true);
        }
    };
</code></pre>

<h2>后续计划</h2>

<p>架构仍需要优化，后面会加入新的功能，未完待续。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Camera2之录像]]></title>
    <link href="http://toughcoder.net/blog/2022/05/06/camera-2-record-video/"/>
    <updated>2022-05-06T22:38:03+08:00</updated>
    <id>http://toughcoder.net/blog/2022/05/06/camera-2-record-video</id>
    <content type="html"><![CDATA[<p><a href="http://toughcoder.net/blog/2022/04/24/camera-2-handling-3a-parameters/">前面的文章</a>都是集中在拍照模式，对于相机来说拍照与录像是两个最为基础的功能，这篇文章来看一下使用Camera2如何实现一个简单的录像功能。</p>

<p><a href=""><img src="https://tse1-mm.cn.bing.net/th/id/R-C.d5e9195041cc351bd041464e996c1333?rik=kBPfq9at8eScog&amp;riu=http%3a%2f%2fpublic.hudl.com%2fassets%2f562f9fbbd4c96106101813f7%2fbball_record.jpg&amp;ehk=eigfVMaCv6ym1Sx4NimQfPnoJ%2frkdPMPlQrVoR9uFm8%3d&amp;risl=&amp;pid=ImgRaw&amp;r=0" title="auto auto" ></a></p>

<!-- more -->


<h2>录像原理和流程</h2>

<p>录像相较于拍照来说，业务逻辑要稍简单一些，因为大部分功能的实现要靠<a href="https://developer.android.com/reference/android/media/MediaRecorder">MediaRecorder</a>。Camera2的API界线划分比较清楚，camera只负责输出图像帧，至于如何编码成为视频则是多媒体部分（也即MediaRecorder）的事情。</p>

<p>所以，实现录像功能，需要提供一个MediaRecorder，把其Surface作为camera的目标输出，同时作为MediaRecorder的输入，这就建立了它们的连接。</p>

<h3>录像的主要流程</h3>

<p>有以下几个关键的步骤需要做：</p>

<h4>1. 选择要使用的分辨率</h4>

<p>从CameraAgent中读取支持的分辨率。简单起见，可以用全高清来当默认值width=1920，height=1080，fps=30。</p>

<h4>2. 准备目标Surface</h4>

<p>可以用<a href="https://developer.android.com/reference/android/media/MediaCodec">MediaCodec</a>来创建一个Surface，用<a href="https://developer.android.com/reference/android/media/MediaCodec#createPersistentInputSurface(">createPersistentInputSurface</a>)方法，这个会传给CameraAgent用作配置session。</p>

<h4>3. 准备MediaRecorder</h4>

<p>创建实例，用步骤1作为video配置，步骤2 的Surface当作input surface，然后还要prepare，否则一些资源不会生效如Surface的buffer。</p>

<pre><code class="java">    private void setupMediaRecorder(VideoOutputConfig mode) {
            recorderSurface = MediaCodec.createPersistentInputSurface();

            mediaRecorder = createRecorder(mode.width, mode.height, mode.fps);
            try {
                mediaRecorder.prepare();
            } catch (IOException e) {
                Log.w(LOG_TAG, "failed to prepare MediaRecorder: " + e.getMessage());
            }
        }
    }

    private MediaRecorder createRecorder(int width, int height, int fps) {
        MediaRecorder recorder;
        if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.S) {
            recorder = new MediaRecorder(context);
        } else {
            recorder = new MediaRecorder();
        }

        recorder.setAudioSource(MediaRecorder.AudioSource.MIC);
        recorder.setVideoSource(MediaRecorder.VideoSource.SURFACE);
        recorder.setOutputFormat(MediaRecorder.OutputFormat.MPEG_4);
        recorder.setOutputFile(emptyVideoFile(context));
        recorder.setVideoEncodingBitRate(1_0_000_000);
        recorder.setVideoSize(width, height);
        recorder.setVideoFrameRate(fps);
        recorder.setVideoEncoder(MediaRecorder.VideoEncoder.H264);
        recorder.setAudioEncoder(MediaRecorder.AudioEncoder.AAC);
        recorder.setInputSurface(recorderSurface);

        recorder.setOnErrorListener(this);
        recorder.setOnErrorListener(this);
        return recorder;
    }
</code></pre>

<p>到此，Surface和MediaRecorder就处于ready状态了</p>

<h4>4. 使用常规view finder的Surface和第2步的Surface来启动预览</h4>

<p>就是启动常规的预览即可：</p>

<pre><code class="java">cameraAgent.startPreview(Arrays.asList(previewSurface, recorderSurface));
</code></pre>

<h4>5. 现在就处于Ready状态了，可以随时录像</h4>

<h4>6. 调用MediaRecorder#start/stop/pause/resume来录像</h4>

<h2>录像的分辨率选择</h2>

<p>尺寸比例可以固定在16：9，因为这是较为通用的比例尺寸：</p>

<pre><code class="java">    public List&lt;VideoOutputConfig&gt; calculateVideoRecordMode() {
        StreamConfigurationMap configurationMap = characteristics.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
        List&lt;Size&gt; supportedSizes = Arrays.asList(configurationMap.getOutputSizes(MediaRecorder.class));
        return supportedSizes.stream()
                .filter(size -&gt; {
                    final float ratio = (float) size.getWidth() / (float) size.getHeight();
                    return Math.abs(ratio - Config.PictureRatio.WIDE.ratio) &lt;= CameraSize.EPS;
                })
                .map(size -&gt; {
                    float rfps = (float) configurationMap.getOutputMinFrameDuration(MediaRecorder.class, size) / 1_000_000_000.0f;
                    int fps = rfps &gt; 0f ? (int) (1.0f / rfps) : 0;
                    return new VideoOutputConfig(size.getWidth(), size.getHeight(), fps);
                }).filter(vrm -&gt; vrm.fps &gt; 0)
                .collect(Collectors.toList());
    }
</code></pre>

<h2>录像之闪光灯</h2>

<p>闪光灯主要是用于拍照，但录像也是支持闪光灯的，当然还是要看硬件的配置，如果characteristics.get(<a href="https://developer.android.com/reference/android/hardware/camera2/CameraCharacteristics#FLASH_INFO_AVAILABLE">CameraCharacteristics.FLASH_INFO_AVAILABLE</a>)为true，那就可以在录像中使用闪光灯，不过一般情况下，只有OFF和TORCH两种模式，因为录像是一个持续的输出帧的过程，其余的模式没有意义。</p>

<h2>开始录像之后的流程</h2>

<p>录像准备妥当后，准备目标文件，监听用户事件，按下快门后开始录像，再次点击后结束录像，然后释放MediaRecorder，最后把文件写入媒体数据库。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Camera2拍照之3A处理]]></title>
    <link href="http://toughcoder.net/blog/2022/04/24/camera-2-handling-3a-parameters/"/>
    <updated>2022-04-24T21:17:03+08:00</updated>
    <id>http://toughcoder.net/blog/2022/04/24/camera-2-handling-3a-parameters</id>
    <content type="html"><![CDATA[<p><a href="http://toughcoder.net/blog/2022/04/13/camera-2-take-snapshot/">前面一篇文章</a>介如了如何进行拍照，但那是最为基本的操作，还不够，作为相机还需要处理3A相关的参数和状态，以得到更好的拍照效果，这篇文章就来详细的学习一下如何处理最基础的3A。</p>

<p><a href=""><img src="https://3q9z5d3wyxnn1bhwik46zlyr-wpengine.netdna-ssl.com/wp-content/uploads/2013/01/mattcameradiagram2.png" title="auto auto" ></a></p>

<script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>


<script>mermaid.initialize({startOnLoad:true});</script>




<!-- more -->


<h2><a href="https://source.android.com/devices/camera/camera3_3Amodes">基础知识</a></h2>

<p>3A，也即是AF &ndash; <a href="https://en.wikipedia.org/wiki/Autofocus">Auto Focus</a>（自动对焦）, <a href="https://www.sony.com/electronics/support/articles/00014979">AE</a> &ndash; Auto Exposure（自动爆光）和 AWB &ndash; Auto White Balance（自动白平衡），是拍照里面最为基础的三参数，对拍照的效果有直接影响。</p>

<p>大多数情况下，是不需要做特别的处理的，只要是一款合格的相机（无论是单反，卡片机，还是智能手机）都有自动模式，也就是说相机硬件系统会运行在一组自动的参数之下，也是默认的，基本的和常用的模式，用户不需要特别调整。只有在手动模式，或者称为高级模式的时候，才需要用户去设置特别的参数，以达到更为惊艳的拍照效果，或者应对更为复杂的拍摄条件，当然手动模式需要用户具备专业的知识，否则得到的拍摄效果会比auto模式还要差。</p>

<h2>常规的参数设置</h2>

<p> 旧的API中只需要从Camera对象中拿到Parameters对象，它像一个Map，更改其中的值就可以了。Camera 2略有变化 ，但总体思想是一样的，仍是类似于Map，键-值式的设置具体的参数，我们来看一下。</p>

<h3>关键的对象</h3>

<p>基类是<a href="https://developer.android.com/reference/android/hardware/camera2/CameraMetadata?hl=en">CameraMetadata</a>，它里面以键-值形式定义了参数，类似于一个Map，但它的键并不是单纯的String，值也并不是简单的数据类型如整数或者字串，而是全部都搞成了对象，以一种比较复杂的泛型的方式搞出来的，但就具体使用上面与Map一样，就get/set就好了，虽然都是对象，但都能autobox。</p>

<div class="mermaid">
classDiagram
    CameraMetadata <|-- CaptureRequest
    CameraMetadata <|-- CaptureResult
    CaptureRequest *-- Builder
    
    class CameraMetadata {
    }
    
    class CaptureRequest {
    }
    
    class Builder {
    }
    
    class CaptureResult {
    }
</div>


<p>更为具体的，把下发参数都用<a href="https://developer.android.com/reference/android/hardware/camera2/CaptureRequest?hl=en">CaptureRequest</a>来封装，也就是说上层对底层下发的参数请求，放于此对象中；而从底层读参数的状态，或者说读取某些参数的值则放在了<a href="https://developer.android.com/reference/android/hardware/camera2/CaptureResult?hl=en">CaptureResult</a>里面。</p>

<p>CaptureRequest通常是在下发请求时要去从其Builder中生成的；而CaptureResult则是在CaptureCallback中由底层传上来的。</p>

<h3>参数设置的流程</h3>

<p>根据不同的参数需要可以在预览时，或者拍照时下发参数，方法基本上是一样的，都是通过请求下去的：CameraCaptureSession#setRepeatingRequest，CameraCaptureSession#capture。</p>

<p>在下发请求前需要通过<a href="https://developer.android.com/reference/android/hardware/camera2/CaptureRequest.Builder?hl=en">CaptureRequest#Builder</a>创建请求，而参数就是在此时以键-值方式设置下去的。CaptureRequest是一个Immutable的对象，只能过构建者模式Builder来改变和生成。</p>

<div class="mermaid">
sequenceDiagram
    CameraAgent -&gt;> CameraDevice: createCaptureRequest
    CameraDevice -&#45;&gt;> CameraAgent: CaptureRequest.Builder
    CameraAgent -&gt;> CameraCaptureSession: setRepeatingRequest
    CameraAgent -&gt;> CameraCaptureSession: capture
    CameraCaptureSession -&#45;&gt;> CameraAgent: CaptureCallback.onCaptureStarted
    CameraCaptureSession -&#45;&gt;> CameraAgent: CaptureCallback.onCaptureProgressed
    CameraCaptureSession -&#45;&gt;> CameraAgent: CaptureCallback.onCaptureCompleted
</div>


<h3>常见的预览参数设置</h3>

<p>把3A都设置为Auto即可，能满足需求：</p>

<pre><code class="java">    private void applyCommonParameters(CaptureRequest.Builder requestBuilder) {
        requestBuilder.set(CaptureRequest.CONTROL_MODE, CaptureRequest.CONTROL_MODE_AUTO);
        requestBuilder.set(CaptureRequest.CONTROL_AF_MODE, CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE);
        requestBuilder.set(CaptureRequest.CONTROL_AWB_MODE, CaptureRequest.CONTROL_AWB_MODE_AUTO);
    }

    public void applyForPreview(CaptureRequest.Builder previewBuilder) {
        applyCommonParameters(previewBuilder);

        previewBuilder.set(CaptureRequest.CONTROL_AE_MODE, CaptureRequest.CONTROL_AE_MODE_ON);
        previewBuilder.set(CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER, CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER_IDLE);
        previewBuilder.set(CaptureRequest.CONTROL_AE_LOCK, false);

        previewBuilder.set(CaptureRequest.CONTROL_CAPTURE_INTENT, CaptureRequest.CONTROL_CAPTURE_INTENT_PREVIEW);

        applyFlashMode(previewBuilder, ApplyType.PREVIEW);
    }
</code></pre>

<h3>常见的拍照参数设置</h3>

<p>相较于preview无明显变化，只不过需要添加一些成片相关的设置，如图片质量，旋转等：</p>

<pre><code class="java">    public void applyForStillCapture(CaptureRequest.Builder requestBuilder) {
        applyCommonParameters(requestBuilder);

        requestBuilder.set(CaptureRequest.JPEG_QUALITY, (byte) 92);
        requestBuilder.set(CaptureRequest.JPEG_ORIENTATION, jpegRotation);

        requestBuilder.set(CaptureRequest.CONTROL_CAPTURE_INTENT, CaptureRequest.CONTROL_CAPTURE_INTENT_STILL_CAPTURE);
        requestBuilder.set(CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER, CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER_IDLE);

        applyFlashMode(requestBuilder, ApplyType.CAPTURE);
    }
</code></pre>

<p>如果就是普通的拍照需求，以上这次常规的参数设置就足够了。</p>

<h2>闪光灯</h2>

<p>闪光灯是拍照过程中非常重要的参数，也会显著的影响拍照效果，但与旧的Camera不同，Camera 2中打闪的过程比较复杂，并不是把四种闪光灯模式设置下去就能完事儿的，还涉及AE状态的处理，需要仔细学习和研究。</p>

<p>闪光灯模式，现代的闪光灯共有四种模式：关闭，自动，打开和常亮：</p>

<ul>
<li>关闭 &ndash; 也就是关闭闪光灯，无论什么条件下都不打闪</li>
<li>自动 &ndash; 拍照时，依据AE自动爆光时的光线情况，决定是否需要打闪</li>
<li>打开 &ndash; 拍照时，打闪</li>
<li>常亮 &ndash; 像手电筒一样一直打开闪光灯，预览和拍照时都可生效。注意不能常亮时间太长，否则会引起手机温度过高，耗电过快，甚至可能此起主板烧断。</li>
</ul>


<p>通过在CaptureRequest中设置，键为<a href="https://developer.android.com/reference/android/hardware/camera2/CaptureRequest?hl=en#FLASH_MODE">CaptureRequest.FLASH_MODE</a>，但与旧的不一样，它的值只有三个：</p>

<ul>
<li><a href="https://developer.android.com/reference/android/hardware/camera2/CameraMetadata?hl=en#FLASH_MODE_OFF">FLASH_MODE_OFF</a></li>
<li><a href="https://developer.android.com/reference/android/hardware/camera2/CameraMetadata?hl=en#FLASH_MODE_SINGLE">FLASH_MODE_SINGLE</a></li>
<li><a href="https://developer.android.com/reference/android/hardware/camera2/CameraMetadata?hl=en#FLASH_MODE_TORCH">FLASH_MODE_TORCH</a></li>
</ul>


<p>与预期的四种模式并不匹配，并且如果你下发上面的模式会发现，OFF和TORCH还是符合预期的，分别对应着关闭和常亮。但是即使是SINGLE也并不是打开，它打闪的时间很短，拍照还没有完成就一闪而过，并且具体的打闪的时机，似乎与AE过程并不匹配。前面提到了闪光灯是与自动爆光（AE）过程关联特别大的，只有当AE收敛后打闪才是最合适的时机，并且打闪过程要持续到拍照结束。这里涉及AE状态的处理，并且真实下发的FLASH_MODE并不是SINGLE。</p>

<p><strong>注意</strong>：闪光灯的自动和打开状态仅对拍照过程生效，预览过程是不生效的，所以设置什么值都一样。下面的讨论也是针对拍照过程中的。</p>

<h3>闪光灯打开模式实现方法</h3>

<p>仔细查阅文档可以发现，自动和打开，其实与AE有关，并且AE有两种模式疑似与闪光灯有关系：</p>

<ol>
<li><a href="https://developer.android.com/reference/android/hardware/camera2/CameraMetadata#CONTROL_AE_MODE_ON_AUTO_FLASH">ON_AUTO_FLASH</a></li>
<li><a href="https://developer.android.com/reference/android/hardware/camera2/CameraMetadata#CONTROL_AE_MODE_ON_ALWAYS_FLASH">ON_ALWAYS_FLASH</a></li>
<li><a href="https://developer.android.com/reference/android/hardware/camera2/CameraMetadata#CONTROL_AE_MODE_ON_AUTO_FLASH_REDEYE">ON_AUTO_FLASH_REDEYE</a></li>
</ol>


<p>但直接把AE设置为以上的方式，也不能实现自动打闪和打闪，这两种情况与AE强相关，受AE状态控制，需要处理AE的状态，依据状态的不同然后换思路去实现。</p>

<p>一种实现方式是，真实下发的闪光灯状态是TORCH，但要受AE状态来控制，先触发<a href="https://developer.android.com/reference/android/hardware/camera2/CaptureRequest?hl=en#CONTROL_AE_PRECAPTURE_TRIGGER">AE_PRECAPTURE_TRIGGER</a>，然后监听AE状态变化，当其从<a href="https://developer.android.com/reference/android/hardware/camera2/CameraMetadata#CONTROL_AE_STATE_SEARCHING">SEARCHING</a>变为<a href="https://developer.android.com/reference/android/hardware/camera2/CameraMetadata#CONTROL_AE_STATE_CONVERGED">收敛</a>时，或者变为<a href="https://developer.android.com/reference/android/hardware/camera2/CameraMetadata#CONTROL_AE_STATE_FLASH_REQUIRED">FLASH_REQUIRED</a>时，就直接下发TORCH，直到拍照结束onCaptureCompleted，恢复为正常的状态。</p>

<div class="mermaid">
flowchart TD
    capturePhoto -&#45;> flashMode
    flashMode{FlashMode is ON or AUTO}
    flashMode == No ==> doCapture
    flashMode == Yes ==> preCapture
    preCapture[capture with request<br/>AE_PRECAPTURE_TRIGGER to START]
    preCapture -&#45;> aeSearching
    aeSearching[AE state is searching]
    aeSearching -&#45;> aeConverged
    aeConverged[AE state is converged or flashRequired]
    aeConverged -&#45;> flashTorch
    flashTorch[set flashMode to TORCH]
    flashTorch -&#45;> doCapture
    doCapture -&#45;> onCaptureCompleted
    onCaptureCompleted -&#45;> flashSingle
    flashSingle[set flashMode to SINGLE]
</div>


<p>需要注意的是，预拍照请求是通过单次请求capture下发的，其CaptureCallback可以与预览使用同一个。另外就是AE收敛过程的处理是在onCaptureProgressed中处理的，而其最终的状态是在onCaptureCompleted中的。</p>

<h3>闪灯光自动模式实现方式</h3>

<p>自动模式，与打开时类似，也是当需要打闪的时候直接下发TORCH，只不过，需要在预拍照时，看到AE的状态为FLASH_REQUIRED时，再去下发TORCH，否则就是OFF。</p>

<div class="mermaid">
sequenceDiagram
    CameraAgent -&gt;> CameraCaptureSession: capture AE_PRECAPTURE START
    CameraCaptureSession -&#45;&gt;> CameraAgent: onCaptureProgressed AE PRECAPTURE
    CameraCaptureSession -&#45;&gt;> CameraAgent: onCaptureProgressed AE SEARCHING
    CameraCaptureSession -&#45;&gt;> CameraAgent: onCaptureProgressed AE CONVERGED
    CameraCaptureSession -&#45;&gt;> CameraAgent: onCaptureProgressed AE FLASH_REQUIRED
    CameraAgent -&gt;> CameraCaptureSession: capture FLASH TORCH
    CameraCaptureSession -&#45;&gt;> CameraAgent: onCaptureCompleted
    CameraAgent -&gt;> CameraCaptureSession: setRepeatRequest FLASH SINGLE or OFF
</div>


<p><br/>
总结以上，那么下发flash mode需要做一些修改：</p>

<pre><code class="java">    private void applyFlashMode(CaptureRequest.Builder requestBuilder, ApplyType type) {
        Log.d(LOG_TAG, "applyFlashMode mode " + flashMode + ", applyType " + type);
        FlashMode applyFlashMode = flashMode;

        switch (type) {
            case PRECAPTURE:
            case CAPTURE:
                if ((flashMode == FlashMode.AUTO || flashMode == FlashMode.ON) &amp;&amp; flashRequired)  {
                    applyFlashMode = FlashMode.TORCH;
                }
                break;
            default:
                break;
        }
        Log.d(LOG_TAG, "applyFlashMode apply flash mode " + applyFlashMode);
        requestBuilder.set(CaptureRequest.FLASH_MODE, applyFlashMode.value);

        if (applyFlashMode == FlashMode.AUTO) {
            requestBuilder.set(CaptureRequest.CONTROL_AE_MODE, CaptureRequest.CONTROL_AE_MODE_ON_AUTO_FLASH);
        } else if (applyFlashMode == FlashMode.ON) {
            requestBuilder.set(CaptureRequest.CONTROL_AE_MODE, CaptureRequest.CONTROL_AE_MODE_ON_ALWAYS_FLASH);
        } else {
            requestBuilder.set(CaptureRequest.CONTROL_AE_MODE, CaptureRequest.CONTROL_AE_MODE_ON);
        }
    }
</code></pre>

<p>由于打闪需要，现在capturePhoto方法已变成了三个方法，或者分为三个主要的步骤，一是预拍照，二是拍照，三是拍照后的流程：</p>

<pre><code class="java">    void capturePhoto(Consumer&lt;PhotoCaptureStatus&gt; consumer, PhotoSaveAgent imageSaveAgent, int orientation) {
        Log.d(LOG_TAG, "takeSnapshot");
        if (!cameraDevice.isPresent() || !captureSession.isPresent()) {
            Log.d(LOG_TAG, "takeSnapshot, cannot snap");
            consumer.accept(null);
            return;
        }

        parameters.setFlashRequired(previewCallback.flashRequired());
        final boolean needPreCapture = parameters.needPreCapture();

        Runnable actionPostCapture = null;
        if (needPreCapture) {
            actionPostCapture = () -&gt; {
                Log.d(LOG_TAG, "postCapture reset flash status for post capture.");
                parameters.applyForPreview(requestBuilder);
                previewCallback.setAEState(CameraParameters.Preview3AState.PICTURE_TAKEN);
                try {
                    captureSession.get().setRepeatingRequest(requestBuilder.build(), previewCallback, cameraHandler);
                } catch (CameraAccessException e) {
                    e.printStackTrace();
                }
            };
        }

        final int jpegOrientation = CameraUtils.calculateRelativeRotation(characteristics, orientation);
        parameters.setJpegRotation(jpegOrientation);
        final PhotoStillCapture stillCapture = new PhotoStillCapture(consumer, imageSaveAgent, actionPostCapture);

        final Runnable action = () -&gt; {
            Log.d(LOG_TAG, "capture doCapture");
            try {
                captureSession.get().capture(
                        stillCapture.generateRequest(cameraDevice.get(), imageSaveAgent.getOutputTarget(), parameters),
                        stillCapture.getCaptureCallback(),
                        cameraHandler);
            } catch (CameraAccessException e) {
                e.printStackTrace();
            }
        };

        if (needPreCapture) {
            pendingCaptureAction = action;
            preCapture();
        } else {
            action.run();
            pendingCaptureAction = null;
        }
    }

    private void preCapture() {
        Log.d(LOG_TAG, "preCapture");
        try {
            CaptureRequest.Builder builder = cameraDevice.get().createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
            for (Surface surface : previewSurfaces) {
                builder.addTarget(surface);
            }
            parameters.applyForPreCapture(builder);
            previewCallback.setAEState(CameraParameters.Preview3AState.WAITING_PRECAPTURE);
            captureSession.get().capture(builder.build(), previewCallback, cameraHandler);
        } catch (CameraAccessException e) {
            e.printStackTrace();
        }
    }
</code></pre>

<h2>CameraParameters对象</h2>

<p>为了方便3A以及拍照参数的管理，创建一个新的对象CameraParameters专门用于预览和拍照相关的参数和配置管理。此对象仅与CameraAgent交互，并且由CameraAgent持有。</p>

<div class="mermaid">
classDiagram
    PhotoStillCapture *&#45;- CameraParameters
    CameraAgent *&#45;- CameraParameters
    
    class CameraParameters {
    }
    
    class PhotoStillCapture {
    }
    
    class CameraAgent {
    }
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Camera 2学习之拍照基础]]></title>
    <link href="http://toughcoder.net/blog/2022/04/13/camera-2-take-snapshot/"/>
    <updated>2022-04-13T21:31:01+08:00</updated>
    <id>http://toughcoder.net/blog/2022/04/13/camera-2-take-snapshot</id>
    <content type="html"><![CDATA[<p>前面<a href="http://toughcoder.net/blog/2022/03/04/camera-2-preview-and-improvement/">一篇文章</a>讲解了如何建立预览，下一步就是进行拍照了，这是相机类的核心业务，TL;DR。</p>

<p><a href=""><img src="https://tse4-mm.cn.bing.net/th/id/OIP-C.teE5837-ZJPLgV6e410swAHaFN?pid=ImgDet&amp;rs=1" title="auto auto" ></a></p>

<script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>


<script>mermaid.initialize({startOnLoad:true});</script>




<!-- more -->


<h2>拍照的基本流程</h2>

<p>先简单的总结 一下，有个印象，后面会逐一详细的讲解：</p>

<ol>
<li>需要一个目标输出，以接收camera的输出。Camera2的API界线划分的比较清楚，Camera只负责拍照成像，并且输出的结果不再像以前那样直接返回一个jpeg byte array，是一个中间结果，需要一个目标输出进行收集并处理。</li>
<li>需要一个CameraCaptureSession.CaptureCallback，以监听拍照流程状态</li>
<li>需要存储模块做最终的结果保存</li>
</ol>


<p>整体架构图：</p>

<div class="mermaid">
classDiagram
    OnImageAvailableListener  <|-- PhotoSaveAgent
    PhotoWriteTask --|> Runnable
    PhotoResultObserver <|-- PhotoSaveAgent
    PhotoSaveAgent ..|> PhotoWriteTask
    CaptureCallback  <|-- PhotoStillCapture
    PhotoSaveAgent *-- PhotoResult
    PhotoWriteTask *-- PhotoResult
    PhotoResultObserver --* PhotoStillCapture   
    class PhotoSaveAgent {
        imageReader
        photoQueue
        executor
        +config(int width, int height, int format)
        +Surface getOutputTarget()
        onImageAvailable()
        onCaptureStart()
        onCaptureComplete()
    }
    
    class OnImageAvailableListener {
        &lt;&lt;interface&gt;&gt;
        onImageAvailable(Image image)
    }
    
    class Runnable {
        &lt;&lt;interface&gt;&gt;
        run()
    }
    
    class PhotoWriteTask {
        &lt;&lt;interface&gt;&gt;
        run()
    }
    
    class PhotoResultObserver {
        &lt;&lt;interface&gt;&gt;
        onCaptureStart(CaptureRequest request, long timestamp, long frame, String filename)
        onCaptureComplete(CaptureRequest request, CaptureResult result)
    }
    
    class PhotoResult {
        CaptureRequest captureRequest
        long timestamp
        long frameNumber
        String filename
        CaptureResult captureResult
        Image image
    }
    
    class CaptureCallback {
        &lt;&lt;interface&gt;&gt;
        onCaptureStarted()
        onCaptureProgressed()
        onCaptureCompleted()
        onCaptureFailed()
    }
    
    class PhotoStillCapture {
        Date dateTaken
        String filename
        Consumer consumer
        PhotoResultObserver resultObserver
        +generateRequest()
        +generateCaptureCallback()
    }
</div>


<h2>存储模块</h2>

<p>存储模块的主要职责是提供目标输出给CameraAgent，收集拍照结果，并做后续的保存工作。它与CameraAgent是独立开来的，并没有直接的关系。</p>

<pre><code>save
  |-- PhotoSaveAgent
  |-- PhotoWriteTask
</code></pre>

<h3>关键的组件</h3>

<h4>ImageReader拍照结果收集器</h4>

<h4>PhotoSaveAgent用以封装和对外交互</h4>

<h4>PhotoWriteTask专门负责把jpeg结果进行文件保存和媒体库的记录创建</h4>

<h4>结果队列</h4>

<p>因为结果会来源于ImageReader#OnImageAvailable和onCaptureComplete，需要合并两个异步回调的以合成最终结果，并且两个回调均是异步的，先后顺序 也不一样，因此需要一个队列。</p>

<p>因为查询比较多，所以，这里用一个哈希表来当作队列，键为CaptureRequest，而值为PhotoResult。</p>

<h3>线程模型</h3>

<p>会有一个HandlerThread，以保证存储模块相关的操作全部都发生在自己的HandlerThread里面，这里存储模块的主要的工作线程。当与外部交互 时，特别是有外部的回调过来时，都要及时的转入自己的工作线程进行后续处理，以保证线程的安全性。</p>

<p>ImageReader的回调OnImageAvailable也要放在自己的工作线程中。</p>

<p>还需要一个线程池专门用于jpeg结果的保存。因为文件的I/O是CPU密集型的耗时操作，如果放在主工作线程中，会造成阻塞，并且可能会多个拍照结果要处理，所以需要一个专门的线程池。</p>

<h3>对外交互</h3>

<h4>接收camera size</h4>

<p>因为创建ImageReader时需要指定一个尺寸，而这个尺寸必须 来自于camera，也就是说必须 是camera针对 某一配置所能支持的尺寸，并要符合一定的约束。这个尺寸最终会作用到目标输出Surface上面，从而影响拍照结果。</p>

<h4>提供一个返回Surface的接口给外部</h4>

<p>Camera 2的所有输出都是以Surface形式的中间结果（实质上都是一些buffer），所以需要提供一个Surface给CameraAgent。这个Surface可以从创建好了的ImageReader中直接获取。</p>

<h4>实现一个拍照结果观察者</h4>

<p>除了上述三个以外，不暴露任何公开的方法。</p>

<h3>主要工作流程</h3>

<p>此模块需要在Activity中进行初始化，和生命周期的管理，比如在onCreate时进行初始化，在onDestroy中进行销毁。</p>

<p>初始化时，要先准备工作线程HandlerThread，并启动。之后要把初始化工作都尽可能的放在工作线程中，以不阻塞外部调用线程。</p>

<p>之后是创建ImageReader，这个需要外部输入尺寸，一旦ImageReader创建完成，就会处于ready状态。</p>

<p>PhotoSaveAgent是对外交互的对象，在CameraContext中会使用此对象，主要是：</p>

<ol>
<li>当CameraAgent对象创建好了后，计算出来了picture size后，通知camera size给PhotoSaveAgent，PhotoSaveAgent知道此size后便可以创建ImageReader</li>
<li>拍照时，获取目标输出Surface，来源是第1步创建好后的ImageReader</li>
<li>拍照时接收拍照状态</li>
</ol>


<div class="mermaid">
stateDiagram-v2
    [*] &#45;&#45;> Setup
    Setup &#45;&#45;> Config
    Config &#45;&#45;> ReadyForImage
    ReadyForImage &#45;&#45;> CollectPhotoResult
    CollectPhotoResult &#45;&#45;> SavePhoto
    SavePhoto &#45;&#45;> ReadyForImage
    SavePhoto &#45;&#45;> TearDown
    TearDown &#45;&#45;> [*]
</div>


<h4>拍照结果收集</h4>

<p>一旦PhotoSaveAgent处于ready状态后，就可以随时收集拍照结果，拍照的结果全部是以回调的形式被动通知的，二个是来自于拍照模块，一个是ImageReader：</p>

<ol>
<li>拍照开始</li>
<li>拍照结束</li>
<li>ImageReader通知onImageAvailable</li>
</ol>


<p>需要注意，前面的三个回调拍照开始肯定 最先来，但后面的拍照结束和onImageAvailable谁先谁后真不一定，理论上来说是拍照结束来的早一些，但也不绝对，因此在逻辑处理上不能强依赖这两者的午后顺序。</p>

<p>主要的流程是：</p>

<ol>
<li>拍照开始时，在结果队列中添加记录，以CaptureRequest为key，并创建PhotoResult对象；</li>
<li>拍照结束回调中，以CaptureRequest为key，查询结果，向PhotoResult对象添加CaptureResult，并检查PhotoResult的状态，如果PhotoResult的CaptureResult和Image对象都齐全了，就说明拍照结果已集齐，这时就可以移除队列并进行保存了；</li>
<li>在onImageAvailable中，流程稍复杂些，因为这个回调只有一个Image对象，需要与队列中的PhotoResult对象进行匹配，就是通过拍照时的timestamp进行匹配，这是唯一的标识了，遍历队列，如果找到了就更新PhotoResult，并检查是否集齐，如已集齐则移除队列并进行结果保存。</li>
</ol>


<p>另外需要注意的是，拍照开始和拍照结束两个回调的调用线程不确定，所以需要进行转换，先转到PhotoSaveAgent的工作线程中再去处理，这样可以保证PhotoSaveAgent的所有操作都在自己的线程中，不需要再做额外的线程安全性保护。</p>

<h4>拍照结果保存</h4>

<p>在拍照结果回调中，以及onImageAvailable回调中检查PhotoResult是否集齐，集齐后，就可以进行结果保存。</p>

<p>主要流程如下：</p>

<ol>
<li>创建PhotoWriteTask，它实现了Runnable接口，以方便在线程池中使用</li>
<li>向线程池提交任务</li>
<li>在创建任务的时候，要把需要的信息都保存下来。特别需要注意的是，需要从Image中把jpeg byte array拷贝出来。因为ImageReader内部会用Image池子去不断的接收从外部输入（拍照时就是camera sensor）的结果，所以onImageAvailable中传过来的Image需要尽快的释放（即Image#close），以保证ImageReader能正常工作。PhotoWriteTask虽然是单独的线程池，但文件的I/O过程不可控，可能长也可能短，假如简单的持有Image对象，可能会导致Image对象无法及时被释放，从而导致ImageReader不能正常工作。因此需要在创建任务的时候就赶紧把jpeg bytes从Image中拷贝出来。</li>
<li>具体的写入过程比较清晰，向MediaProvider中写入文件即可。</li>
</ol>


<h2>拍照模块</h2>

<p>这是最为核心的一部分。</p>

<pre><code>snapshot
    |-- PhotoCaptureStatus
    |-- PhotoResult
    |-- PhotoResultObserver
    |-- PhotoStillCapture
</code></pre>

<h3>关键组件</h3>

<ol>
<li>PhotoResultObserver，拍照结果观察者接口，用于向外部通知拍照结果，两个方法，一个是拍照开始，一个是拍照结束。注意拍照失败也是调用拍照结束，只不过没有CaptureResult。</li>
<li>PhotoResult，这是合成后的拍照结果对象，里面包含着拍照结果的一切信息，如文件名，参数，CaptureRequest，CaptureResult和Image。是一个POJO，仅做状态和数据的保存，无逻辑。</li>
<li>PhotoStillCapture，可理解为拍照对象，用以封装拍照参数，生成CaptureRequest和处理CaptureCallback。</li>
</ol>


<h3>线程模型</h3>

<p>这属于核心业务，所以它是在CameraContext的工作线程中的。</p>

<h3>对外交互</h3>

<p>通过PhotoResultObserver来通知外部拍照的结果状态。</p>

<h3>工作流程</h3>

<p>CameraContext中拉回拍照接口，并转入到自己的工作线程中。CameraAgent增加拍照接口，这是主要的功能入口。</p>

<div class="mermaid">
sequenceDiagram
    CameraActivity ->> CameraAgent: takePhoto
    CameraAgent ->> PhotoSaveAgent: getOutputTarget
    CameraAgent -&#45;>> CameraActivity: started
    CameraAgent -&#45;>> CameraActivity: ongoing
    CameraAgent -&#45;>> PhotoSaveAgent: onCaptureStart
    CameraAgent -&#45;>> CameraActivity: completed
    CameraAgent -&#45;>> PhotoSaveAgent: onCaptureComplete
    PhotoSaveAgent ->> PhotoWriteTask: savePhoto
    PhotoWriteTask -&#45;>> CameraActivity: thumbnailArrived
</div>


<p>CameraAgent会在其capturePhoto方法，创建一个PhotoStillCapture对象，然后调用CameraCaptureSession#capture方法进行拍照。拍照请求由PhotoStillCapture生成，CaptureCallback亦由PhotoStillCapture对象处理。</p>

<p>创建PhotoStillCapture对象是会锁定一些参数，如当前的旋转，文件名字（通常以时间戳为文件名字）， 以及PhotoResultObserver。</p>

<p>生成拍照请求CaptureRequest时，会传入一些拍照需要的参数，如旋转，如图片质量等等。</p>

<p>在CatpureCallback中，做一些简单处理，然后回调PhotoResultObserver。</p>

<p>到此，拍照模块的事情 就做完，它就要是拍照的前期工作，与外部做连接，下发请求就基本上完整了。拍照结果的收集则是存储模块的事情 了。</p>

<h2>状态反馈</h2>

<p>从整个拍照交互来说，也是需要状态反馈的，最为基础的交互逻辑是，为了保证拍照的成功率，当下发拍照请求后，到拍照结束前，也就是CaptureCallback#onCaptureCompleted或者CaptureCallback#onCaptureFailed这两个回调回来之前，是不可以下发新的拍照请求的。</p>

<div class="mermaid">
classDiagram
    CameraActivity &#45;&#45;|> Consumer
    Consumer &#45;&#45;&ast; PhotoStillCapture
    CaptureCallback <|&#45;&#45; PhotoStillCapture
    
    class Consumer {
        &lt;&lt;interface&gt;&gt;
        +accept(PhotoCaptureStatus status)
    }
    
    class CameraActivity {
    }
    
    class PhotoStillCapture {
        consumer
    }
    
    class CaptureCallback {
        &lt;&lt;interface&gt;&gt;
        onCaptureStarted()
        onCaptureProgressed()
        onCaptureCompleted()
        onCaptureFailed()
    }
</div>


<p>那么交互 层面也需要知道拍照状态，以方便进行UI管控，比如说当下发了拍照请求后，就把快门shutter设置为disabled，在拍照结束后再恢复为enabled的；此外还有拍照动画，也需要知道状态。</p>

<p>但UI交互层只知道状态就可以了，并不需要特别的数据，所以 这一路的状态通过简单的Consumer即可实现，仅在拍照模块中定义一些简单的状态就可以了：</p>

<pre><code class="java">public enum PhotoCaptureStatus {
    STARTED,
    ONGOING,
    FAILED,
    COMPLETED
}
</code></pre>

<p>因为拍照是由UI层触发的，所以在调用CameraContext时，就提供一个接收状态的Consumer就可以了，这样就把UI层和逻辑层分离开了，逻辑层接收Consumer作为参数，在关键的节点就回报状态；UI层负责处理感兴趣的状态就可以了：</p>

<pre><code class="java">public void takePhoto(View view) {
        shutterView.setEnabled(false);

        cameraFactory.takePhoto(status -&gt; mainHandler.post(() -&gt; captureStatusListener.accept(status)));
    }
</code></pre>

<p>当然别忘记了，在Consumer中要做线程切换，UI的处理只以在主线程中。</p>

<h2>缩略图处理</h2>

<p>缩短略图是一个非常重要的拍照结果展示，用以告诉用户拍照成功了，并且是预览结果成片的入口，因此需要做二个事情：</p>

<ol>
<li>监听拍照结果，注意这里并不是说要监听拍照状态，而是要监听拍照结果，因为只有得到最终结果jpeg array后，才可以从这里创建缩略图，并展示 出来。</li>
<li>点击缩略图时要能够进行结果成片的展示，所以，还需要知道拍照结果的文件路径，或者说Uri</li>
</ol>


<p>以上两个信息，都在PhotoSaveAgent里面，因此需要建立UI层与存储模块之间的连接，但其实存储层只是一个数据来源，它并不负责缩略图的业务，而且缩略图的来源可能的不止存储模块，还能来源于直接的数据库查询。</p>

<div class="mermaid">
classDiagram
    ThumbnailObserver <|-- CameraActivity
    CameraActivity --* Thumbnail
    ThumbnailObserver --* PhotoSaveAgent
    
    class CameraActivity {
        thumbnailArrived(Thumbnail thumbnaill)
    }
    
    class PhotoSaveAgent {
        +addThumbnailObserver()
    }
    
    class Thumbnail {
        bitmap
        uri
    }
    
    class ThumbnailObserver {
        &lt;&lt;interface&gt;&gt;
        thumbnailArrived(Thumbnail thumbnail)
    }
</div>


<p>为此，新建一个缩略图模块，里面有一个Thumbnail对象，是一个POJO用以代表缩略图的相关信息，如Bitmap和Uri；还有一个ThumbnailObserver的接口，用以让数据源告诉观察者，一个新的缩略图对象生成了。</p>

<pre><code class="java">public class Thumbnail {
    private final Uri uri;
    private final String mime;
    private final Bitmap bitmap;

    public Thumbnail(Uri uri, String mime, Bitmap bitmap) {
        this.uri = uri;
        this.mime = mime;
        this.bitmap = bitmap;
    }

    public Bitmap getBitmap() {
        return bitmap;
    }

    public Intent generateAction() {
        Intent intent = new Intent(Intent.ACTION_VIEW);
        intent.setDataAndType(uri, mime);
        return intent;
    }
}
</code></pre>

<pre><code class="java">public interface ThumbnailObserver {
    void thumbnailArrived(Thumbnail thumbnail);
}
</code></pre>

<p>如此，UI层与PhotoSaveAgent就分离开来了，它们之间的联系只有ThumbnailObserver接口，UI层就实现接口，负责收到缩略图后的展示工作：</p>

<pre><code class="java">   private final ThumbnailObserver thumbnailObserver = thumbnail -&gt; mainHandler.post(() -&gt; updateThumbnail(thumbnail));

    private void updateThumbnail(Thumbnail thumbnail) {
        thumbnailSwitcher.setEnabled(true);
        thumbnailSwitcher.setTag(thumbnail);

        ((ImageView) thumbnailSwitcher.getNextView()).setImageBitmap(thumbnail.getBitmap());

        thumbnailSwitcher.showNext();
    }

    // when init PhotoSaveAgent, register the thumbnail observer
    imageSaveAgent.addThumbnailObserver(thumbnailObserver);

    public void viewLastPhoto(View view) {
        if (thumbnailSwitcher.getTag() == null) {
            Log.d(LOG_TAG, "No thumbnail, you should take photo first.");
            return;
        }
        Thumbnail thumbnail = (Thumbnail) thumbnailSwitcher.getTag();
        Intent action = thumbnail.generateAction();
        try {
            startActivity(action);
        } catch (ActivityNotFoundException e) {
            Log.d(LOG_TAG, "Unfortunately, we cannot view the photo.");
        }
    }
</code></pre>

<p>而对于PhotoSaveAgent则需要在PhotoWriteTask里面，最后一步，也即文件保存完毕后，生成缩略图，因为是需要Uri的，所以必须是要在最后才能生成缩略图，并通过ThumbnailObserver回调：</p>

<pre><code class="java">   // in PhotoWriteTask
   public void run() {
        ///// other codes

        Thumbnail t = generateThumbnail(fileUri);
        for (ThumbnailObserver to : thumbnailObservers) {
            to.thumbnailArrived(t);
        }
    }

    private Thumbnail generateThumbnail(Uri uri) {
        return new Thumbnail(uri, mime, extractThumbnailBitmap(jpeg));
    }

    private Bitmap extractThumbnailBitmap(byte[] jpegArray) {
        int target = 480;
        BitmapFactory.Options options = new BitmapFactory.Options();
        options.inJustDecodeBounds = true;
        BitmapFactory.decodeByteArray(jpegArray, 0, jpegArray.length, options);
        options.inSampleSize = Math.min(options.outWidth, options.outHeight) / target;
        options.inJustDecodeBounds = false;
        Bitmap bitmap = BitmapFactory.decodeByteArray(jpegArray, 0, jpegArray.length, options);
        Matrix matrix = new Matrix();
        matrix.postRotate(jpegOrientation);
        Bitmap rotated = Bitmap.createBitmap(bitmap, 0, 0, bitmap.getWidth(), bitmap.getHeight(), matrix, true);
        if (rotated != bitmap) {
            bitmap.recycle();
        }
        return rotated;
    }
</code></pre>

<h2>拍照动画</h2>

<p>拍照动画的目的就在于给用户一个直观 的感觉，特别是拍照开始了，至于拍照结束倒是不用特别的，这人一般在缩略图那里体现。</p>

<p>主要做两个动画，一个是快门shutter的动画，这个是在快门点击时就可以去做了，主要是一个缩放的动画，把缩放的动画正着放一遍（缩小0.75倍），再reverse（放大到正常大小）即可：</p>

<pre><code class="Java">public void takePhoto(View view) {
        shutterView.setEnabled(false);

        ScaleAnimation anim = new ScaleAnimation(1f, 0.75f, 1f, 0.75f,
                Animation.RELATIVE_TO_SELF, 0.5f, Animation.RELATIVE_TO_SELF, 0.5f);
        anim.setDuration(Config.CAPTURE_ANIM_DURATION / 2);
        anim.setInterpolator(new AccelerateDecelerateInterpolator());
        anim.setFillAfter(true);
        anim.setRepeatMode(Animation.REVERSE);
        anim.setRepeatCount(1);
        shutterView.startAnimation(anim);

        cameraFactory.takePhoto(status -&gt; mainHandler.post(() -&gt; captureStatusListener.accept(status)));
    }
</code></pre>

<p>另外一个就是在拍照开始时的动画，这个动画的时机是在硬件真的开始拍照时做，也即是要在CaptureCallback#onCaptureStarted时去做，需要特别注意的是，这个时间是由硬件决定的，所以只有在onCaptureStarted回调时去做才是最恰当的。</p>

<p>至于动画的形式，一般是通过预览区域的闪动实现，比如可以用一个与预览Surface一样大小的View，改变它的颜色，给用户一种预览闪动的效果即可。这里的overlayView是一个盖在预览上面的透明的View，在做动画时给它设置为半透明的白色：</p>

<pre><code class="java">     private final Consumer&lt;PhotoCaptureStatus&gt; captureStatusListener = status -&gt; {
        Log.d(LOG_TAG, "capture status " + status);
        statusView.setText("Capture Status: " + status);
        if (status == PhotoCaptureStatus.STARTED) {
            overlayView.setBackground(new ColorDrawable(Color.argb(150, 255, 255, 255)));
            mainHandler.postDelayed(() -&gt; overlayView.setBackground(null), Config.CAPTURE_ANIM_DURATION);
        } else if (status == PhotoCaptureStatus.COMPLETED) {
            shutterView.setEnabled(true);
        } else if (status == PhotoCaptureStatus.FAILED) {
            shutterView.setEnabled(true);
        }
    };
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Camera 2教程之预览与加强]]></title>
    <link href="http://toughcoder.net/blog/2022/03/04/camera-2-preview-and-improvement/"/>
    <updated>2022-03-04T19:27:56+08:00</updated>
    <id>http://toughcoder.net/blog/2022/03/04/camera-2-preview-and-improvement</id>
    <content type="html"><![CDATA[<p><a href="http://toughcoder.net/blog/2022/02/28/camera2-api-made-easy/">前一篇文章</a>讲解了如何使用这套新的API，但仍有很多可以提升的空间，这篇重点来讲讲，如何提升预览画质和做一些加强。</p>

<p><a href=""><img src="https://www.edumobile.org/wp-content/uploads/2015/05/Camera-Preview-Example-in-Android-Programming.jpg" title="auto auto" ></a></p>

<!-- more -->


<h2>线程模型</h2>

<p>因为相机是属于硬件，操作起来可能会耗时，这套新的API也特别注意，因此加了很多异步化处理，所有的请求结果全是通过回调来进行的，并且需要调用者来指定一个回调所使用的线程。因此，我们需要一个专门用于camera操作的线程，用HandlerThread就可以，并把它控制在Activity的生命周期之中，比如在onCreate时启动此线程，在onDestroy时关闭。</p>

<pre><code class="java">    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        attachCameraThread();
    }

    @Override
    protected void onDestroy() {
        super.onDestroy();
         detachCameraThread();
    }
</code></pre>

<p>所有与camera相关的操作，均要在相机专属的HandlerThread中调用，与其他线程（如主线程）的交互均通过回调处理。</p>

<h2>关键对象</h2>

<p>为了进一步的封装和方便管理，需要两个关键对象的封装。</p>

<h3>CameraContext</h3>

<p>一个是CameraContext，负责管理相机的线程，外部所有的方法调用均应该通过它来进行，我们的目的是要把所有的相机相关操作封装在自己的线程里面，因此，暴露给外面的接口，必须统一，并且在开放的方法中加入线程检查，如果还没有启动HandlerThread，就报错，调用者需要先attachThread：</p>

<pre><code class="java">public class CameraContext {
    private static final String LOG_TAG = CameraContext.class.getSimpleName();

    private final CameraManagerWrapper cameraManager;
    private volatile HandlerThread cameraManageThread;
    private volatile CameraThreadHandler cameraThreadHandler;

    private volatile CameraAgent currentCamera;

    public CameraContext(Context context) {
        cameraManager = new CameraManagerWrapper(context);
    }

    public void attachThread() {
        Log.d(LOG_TAG, "attachThread");
        if (cameraThreadHandler != null) {
            cameraThreadHandler.removeCallbacksAndMessages(null);
        }
        if (cameraManageThread != null &amp;&amp; cameraManageThread.isAlive()) {
            cameraManageThread.quitSafely();
        }
        cameraManageThread = new HandlerThread("Camera Management Thread");
        cameraManageThread.start();
        cameraThreadHandler = new CameraThreadHandler(cameraManageThread.getLooper());
    }

    public void detachThread() {
        Log.d(LOG_TAG, "detachThread");
        if (cameraManageThread != null &amp;&amp; cameraManageThread.isAlive()) {
             cameraManageThread.quitSafely();
        }
    }

    private void checkThread() {
        if (cameraManageThread == null || !cameraManageThread.isAlive()) {
            throw new CameraSetupException("attachThread must be called before any other method invocations.");
        }
    }

    public void openCamera(Consumer&lt;String&gt; consumer) {
        checkThread();
        Runnable actionOpen = () -&gt; {
              // ...
        };
        Message msg = Message.obtain(cameraThreadHandler, actionOpen);
        msg.what = CameraThreadHandler.MSG_OPEN_CAMERA;
        msg.sendToTarget();
    }

    public void closeCamera() {
        checkThread();
        Runnable actionClose = null;
        Message msgClose = Message.obtain(cameraThreadHandler, actionClose);
        msgClose.what = CameraThreadHandler.MSG_CLOSE_CAMERA;
        msgClose.sendToTarget();
    }
}
</code></pre>

<h3>CameraAgent</h3>

<p>还需要对CameraDevice进行封装，把CameraCaptureSession，以及RequestBuilder，封装在内，并且在三大回调Device State Callback，Session State Callback以及Session Capture Callback也都封装在内，因此这些东西的生命周期全都是在CameraDevice内部的。</p>

<p>设计要点：</p>

<ul>
<li>CameraAgent不开放接口给外部，它只能开放给CameraContext使用</li>
<li>对象是对camera device的完整封装，对象本身一直可用，与CameraDevice是否打开无直接关系</li>
<li>随时可以查询静态配置属性，创建对象时就要传入id和CameraCharacteristics</li>
<li>有连接状态，也即打开对应的CameraDevice，动态配置属性查询，以及像启动预览，必须要是连接状态</li>
<li>拍照应该在预览状态内</li>
</ul>


<pre><code class="java">class CameraAgent {
    private static String LOG_TAG = CameraAgent.class.getSimpleName();
    private final String id;
    private final CameraCharacteristics characteristics;
    private final CameraContext.CameraThreadHandler cameraHandler;
    private final Executor executor;

    private Optional&lt;CameraDevice&gt; cameraDevice;
    private Optional&lt;CameraCaptureSession&gt; captureSession;

    private CameraDevice.StateCallback stateCallback = new CameraDevice.StateCallback() {
        @Override
        public void onOpened(@NonNull CameraDevice camera) {
            Log.d(LOG_TAG, "Device Status: onOpened");
            cameraDevice = Optional.of(camera);
        }

        @Override
        public void onDisconnected(@NonNull CameraDevice camera) {
            Log.d(LOG_TAG, "Device Status: onDisconnected");
            cameraDevice = Optional.empty();
        }

        @Override
        public void onError(@NonNull CameraDevice camera, int error) {
            cameraDevice = Optional.empty();
        }
    };

    private CameraCaptureSession.StateCallback regularSessionCallback = new CameraCaptureSession.StateCallback() {
        @Override
        public void onConfigured(@NonNull CameraCaptureSession session) {
            Log.d(LOG_TAG, "Session State: onConfigured");
            captureSession = Optional.of(session);
        }

        @Override
        public void onConfigureFailed(@NonNull CameraCaptureSession session) {
            captureSession = Optional.empty();
        }

        @Override
        public void onClosed(@NonNull CameraCaptureSession session) {
            Log.d(LOG_TAG, "Session State: onClosed");
            super.onClosed(session);
            captureSession = Optional.empty();
        }
    };

    private CameraCaptureSession.CaptureCallback captureCallback = new CameraCaptureSession.CaptureCallback() {
        @Override
        public void onCaptureStarted(@NonNull CameraCaptureSession session, @NonNull CaptureRequest request, long timestamp, long frameNumber) {
            super.onCaptureStarted(session, request, timestamp, frameNumber);
        }
    };

    private CaptureRequest.Builder requestBuilder;

    CameraAgent(String id, CameraCharacteristics cameraCharacteristics, CameraContext.CameraThreadHandler handler) {
        this.id = id;
        this.characteristics = cameraCharacteristics;
        this.cameraHandler = handler;
        executor = command -&gt; handler.post(command);

        cameraDevice = Optional.empty();
        captureSession = Optional.empty();
        previewSize = Optional.empty();
        errorCode = 0;
    }

    String getId() {
        return id;
    }

    boolean connected() {
        return cameraDevice.isPresent();
    }

    CameraDevice.StateCallback getDeviceStateCallback() {
        return stateCallback;
    }

    void connect(@NonNull CameraManagerWrapper wrapper) {
        Log.d(LOG_TAG, "connect");
        wrapper.openCamera(this, cameraHandler);
    }

    void disconnect() {
        Log.d(LOG_TAG, "disconnect");
        if (captureSession.isPresent()) {
            captureSession.get().close();
        }
        if (cameraDevice.isPresent()) {
            cameraDevice.get().close();
        }
    }

    void startPreview() {
    }

    void stopPreview() {
    }
}
</code></pre>

<h2>启动预览</h2>

<p>新的这套API并没有直接设置预览大小或者图片大小的地方，camera的输出都是Surface，底层是通过Surface的大小来做具体的尺寸。本质上都是数据在流动，其实都是buffer，Surface也是buffer，设定了Surface的大小，也就确定了输出buffer的大小，camera硬件也就知道了大小。</p>

<h3>用SurfaceView就可以</h3>

<p>预览是camera的输出，是另外一些组件的输入，API设计已做好了衔接，Surface就是中间的桥梁，Surface作为SurfaceView（可理解为屏幕）的输入，它可以作为camera的输出，由此便把camera的预览显示了出来。在布局文件中用SurfaceView来充当Activity的布局，由此便能得到Surface，再把它塞给camera即可。</p>

<p>需要重点说一下尺寸的约束，想让预览的Surface反应camera预览的尺寸，因此SurfaceView要是wrap_content的。</p>

<pre><code class="xml">&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android="http://schemas.android.com/apk/res/android"
    xmlns:app="http://schemas.android.com/apk/res-auto"
    xmlns:tools="http://schemas.android.com/tools"
    android:layout_width="match_parent"
    android:layout_height="match_parent"
    android:background="@color/black"
    tools:context=".CameraActivity"&gt;

    &lt;net.toughcoder.effectivecamera.AutoFitSurfaceView
        android:id="@+id/view_finder"
        android:layout_width="wrap_content"
        android:layout_height="wrap_content"
        app:layout_constraintTop_toTopOf="parent"
        app:layout_constraintLeft_toLeftOf="parent"
        app:layout_constraintLeft_toRightOf="parent"
        app:layout_constraintBottom_toBottomOf="parent" /&gt;
&lt;/androidx.constraintlayout.widget.ConstraintLayout&gt;
</code></pre>

<h3>如何选择预览尺寸</h3>

<p>输入的约束条件是一个比例，比如流行的预览比例是4：3，16：9或者全屏，这个比例是长边与短边的比值，这个可以作为用户体验层面的一个约束，或者叫做设置，尺寸的选择应该遵守此约束。</p>

<p>另外一个约束就是屏幕尺寸，预览的大小应该能刚好满足屏幕尺寸即可，超出屏幕其实就浪费了，没有必要。</p>

<p>所以，选择预览尺寸的策略就是保证比例和刚好满足屏幕。</p>

<p>每个camera都有支持的一组预览尺寸，按照 我们的策略从其中选择一个就可以了。预览尺寸从静态配置中就可以读得到，不需要连接状态，因此，可以在创建好CameraAgent对象后就可以进行尺寸选择，屏幕尺寸随时可获利，比例约束是一个设置随时可读取，因此这是可行的。</p>

<p>当选择好了预览尺寸后，要把它设置到SurfaceView中去，以让SurfaceView调整自身的大小。</p>

<pre><code class="java">    /*
     * Strategies:
     *  1) preview size should not be bigger than screen, which is not necessary.
     *  2) ratio should match.
     *  3) pick the largest one.
     *  4) if not found, use screen size.
     */
    private Optional&lt;CameraSize&gt; calculatePreviewSize(Point screenSize, float ratio) {
        int width = Math.min(screenSize.x, screenSize.y);
        int height = Math.min(Math.round(width * ratio), screenSize.y);
        final int limit = screenSize.x * screenSize.y;
        Log.d(LOG_TAG, "screen size " + screenSize.x + " x " + screenSize.y +
                ", ratio " + ratio + ", desired width-&gt;" + width + ", height-&gt;" + height);

        StreamConfigurationMap streamMap = characteristics.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
        Size[] surfaceSizes = streamMap.getOutputSizes(Surface.class);
        if (surfaceSizes == null) {
            surfaceSizes = streamMap.getOutputSizes(ImageFormat.PRIVATE);
        }
        List&lt;CameraSize&gt; supportedSize = Arrays.asList(surfaceSizes)
                .stream()
                .map(CameraSize::new)
                .filter(size -&gt; size.height * size.width &lt;= limit)
                .sorted(CameraSize::compare)
                .collect(Collectors.toList());
        Log.d(LOG_TAG, "supportedSize " + supportedSize);
        return supportedSize.stream().filter(size -&gt; size.matchRatio(ratio)).findFirst();
</code></pre>

<h2>确保关闭</h2>

<p>相机是一种硬件资源，当退出的时候要能确保它是关闭状态的，也就是说要确保CameraAgent#disconnect能执行，且要执行完成，执行完成的意思是，你需要收到onDisconnected的回调。</p>

<p>这就要求我们在detachThread，即退出相机线程的时候，要小心处理好尚未来得及执行（如有）的操作，因为所有的操作都会转到相机线程中去，是通过消息队列，所以操作可能还在排队中尚未真正执行。</p>

<p>具体做法是，直接移除掉未得到执行的open和其他操作。如果有pending状态的关闭，则要先让其执行，并且把关闭线程的操作放到CameraDevice State Callcback的onDisconnect中，也就是说待CameraDevice完全关闭完成后，才可以终止相机线程：</p>

<pre><code class="java">    public void detachThread() {
        Log.d(LOG_TAG, "detachThread");
        if (cameraThreadHandler != null) {
            // Drop all pending open actions
            cameraThreadHandler.removeMessages(CameraThreadHandler.MSG_OPEN_CAMERA);
            if (cameraThreadHandler.hasMessages(CameraThreadHandler.MSG_CLOSE_CAMERA)) {
                // Ensure close actions are dispatched.
                try {
                    Thread.sleep(50);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
            // Drop all other messages.
            cameraThreadHandler.removeCallbacksAndMessages(null);
        }
        // TODO: technically speaking, should do this in handler thread
        // since all connect/disconnect are done inside handler thread
        // status might not be synced with caller's thread.
        if (cameraManageThread != null &amp;&amp; cameraManageThread.isAlive()) {
            if (currentCamera != null &amp;&amp; currentCamera.connected()) {
                currentCamera.addDisconnectedAction(() -&gt; cameraManageThread.quitSafely());
            } else {
                cameraManageThread.quitSafely();
            }
        }
    }
</code></pre>
]]></content>
  </entry>
  
</feed>
