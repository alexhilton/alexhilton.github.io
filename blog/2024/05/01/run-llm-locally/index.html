
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>教你用最优雅的方式把玩大模型 - 稀有猿诉</title>
  <meta name="author" content="Alex Hilton">

  
  <meta name="description" content="大模型的信息满天飞，再不把玩大模型就out了，本文教你以优雅的方式来体验大模型，也就是在本地部署开源大模型的保姆级方法。">
  <meta name="keywords" content="LLM, Artificial Intelligence, Deep Learning, Ollama, LM Studio, GPT4ALL">

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="https://alexhilton.github.io/blog/2024/05/01/run-llm-locally">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="稀有猿诉" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="https://code.jquery.com/jquery-3.6.4.min.js" integrity="sha256-oP6HI9z1XaZNBrJURtCoUT5SUnxFr8s3BzRl+cbzUq8=" crossorigin="anonymous"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <script src="/javascripts/toolbar.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.lug.ustc.edu.cn/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.lug.ustc.edu.cn/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

<!-- for Gitment -->
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">

<!-- for favicon -->
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">稀有猿诉</a></h1>
  
    <h2>十年磨一剑，历炼出锋芒，说话千百句，不如码二行。</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com.hk/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:alexhilton.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Home</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/donation">Donation</a></li>
  <li><a href="/about">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">教你用最优雅的方式把玩大模型</h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2024-05-01T23:04:34+08:00'><span class='date'><span class='date-month'>May</span> <span class='date-day'>1</span><span class='date-suffix'>st</span>, <span class='date-year'>2024</span></span> <span class='time'>11:04 pm</span></time>
        
      </p>
    
  </header>


<div class="entry-content"><p><a href="https://www.cloudflare.com/learning/ai/what-is-artificial-intelligence/">人工智能（Artificial Intelligence）</a>几乎与计算机科学一样古老，在二十世纪50年代被首次提出，在60年代就已经形成比较成熟的理论。但受制于算力和数据，直到二十一世纪第一个10年后才有了重大突破（深度学习和CNN），并在第二个10年正式爆发（大模型）。2022年秋OpenAI的ChatGPT 3横空出世，让AI第一次达到「类人」层次，大语言模型（Large Language Model, LLM）也正式进入了公众的视野。自此，大模型开始刷屏和霸榜，人们言必之大模型。如果不折腾折腾大模型，似乎就是原始人，跟别人聊天都插不上话。痛定思痛，今天就来好好研究下大模型以跟上步伐。</p>

<p><a href="/blog/2024/05/01/run-llm-locally/"><img src="https://researchworld.com/uploads/attachments/clr4q0wj95yyf8otdekmzjfy0-large-language-models-for-aspect-based-sentiment-analysis.max.png" title="auto auto" ></a></p>

<!-- more -->


<p>注意：常说的大模型是大语言模型的一种不严谨的简称，更为好的说法是<a href="https://www.cloudflare.com/learning/ai/what-is-large-language-model/">大语言模型（Large Langauge Model）</a>或者用其英文简写LLM，本文可能会混着用。</p>

<p>要了解一个东西最好的方式就先学会使用它，所以我们先从使用大模型开始。</p>

<h2>在本地部署LLM</h2>

<p>体验大模型的方式有很多种，最方便的就是直接使用各大AI大厂提供的聊天机器人如ChatGPT或者ChatGLM。确实很有趣，可以发现LLM与以往的人工智障非常不同的地方在于，它能听懂人话了，并且说的也像人话，也就是说它真的达到了『类人』层次了。</p>

<p>身为开发人猿，光这么把玩太无聊了，最适合开发人猿的玩法就是自己折腾，对的，我们要在本地部署LLM，这样玩起来才更过瘾。省流点说在本地部署有如下好处：</p>

<ul>
<li>可以深入了解LLM的技术栈，亲自折腾一遍才能知道到底有啥，需要啥。</li>
<li>更加安全，且能保护个人隐私。不用多说，直接用Chat服务或者API确实方便，但都是把数据传到别人的服务器上。有些不方便说的话，不适合别人看的，那肯定就不能用了。但使用部署在本地的LLM就不用担心了。</li>
<li>定制LLM以打造个人的知识库或者知识助手。</li>
<li>进行模型微调和深入学习。</li>
<li>积累经验，后续如果上云，有经验了就可以快速部署。</li>
</ul>


<p>在本地部署LLM好处简直不要太多，唯一的缺点就是LLM这玩意儿很费硬件，跑起来比较费钱，要跑的顺畅一些更是大把费钱。</p>

<h2>开源LLM托管平台</h2>

<p>很明显要想本地部署LLM，模型本身必须是开源的，因此只有开源的LLM才能在本地部部署，闭源的模型，只能通过其API使用。</p>

<p>那么，在折腾之前必须要搞懂的事情就是到哪里去找开源的LLM。幸运的是不但现在有很多开源LLM，也有非常方便的LLM托管平台。LLM托管平台就像GitHub之于开源代码一样，各大公司研发和测试完成后就会把LLM发布到托管平台上面，以供人使用。</p>

<p>最为著名的当属<a href="https://huggingface.co/models">HuggingFace</a>了，它不但提供LLM的托管，还有一个几乎成为业界标准的<a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">LLM评估系统</a>，定期发布最新模型的评估，以帮助大家选择合适的LLM。而且还提供了下载和使用LLM的Python库，即<a href="https://pypi.org/project/transformers/">著名的transformers</a>。但很可惜，我们无法访问（你懂得）。</p>

<p>莫慌，对于无法访问的技术网站，一定有<a href="https://hf-mirror.com/">国内的镜像</a>的，非常的好用，而且访问速度很快。</p>

<p><a href="https://mirrors.tuna.tsinghua.edu.cn/">清华大学</a>也曾有镜像，不过后来不能用了。</p>

<h2>如何在本地运行LLM</h2>

<p>下面介绍几种非常方便的，五分钟就能学会的本地部署和运行LLM的方式。</p>

<h3>Ollama</h3>

<p><img src="https://guidady.com/wp-content/uploads/2023/07/Ollama.png" alt="" /></p>

<p>最为方便的方式就是使用<a href="https://ollama.com/">Ollama</a>，它使用起来特别的方便，<a href="https://github.com/ollama/ollama">安装好以后</a>，直接一句就能运行并使用LLM了：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>ollama run llama3
</span></code></pre></td></tr></table></div></figure>


<p>这就能运行Meta的最新的LLaMA3模型。当然了，运行具体模型前最好先读一读其文档，确认一下硬件配置是否满足模型要求。像家庭比较贫困的笔者用的是乞丐版的MBP（16G RAM+4G GPU）只能选择8B以内的模型，家庭条件比较好的可以上13B的模型，而33B的最好不要试了。</p>

<p>Ollama非常的好用，它本身是C/S式的，也就是说它会启一个小型的HTTP server以运行LLM，除了直接使用Ollama自己的终端以外，也可以充当模型API给其他工具使用，比如像<a href="https://python.langchain.com/docs/get_started/introduction">LangChain</a>就可以无缝对接Ollama。</p>

<p>它的缺点就是它是源于Mac，对Mac最为友好，其他系统如Windows和Linux是后来才支持的。另外就是使用起来比较简陋，仅有一个命令行终端，所以比较好的方式是使用Ollama来管理和运行LLM，但是再用其他工具来构建比较好用的终端。</p>

<p>扩展阅读：</p>

<ul>
<li><a href="https://www.freecodecamp.org/news/how-to-run-open-source-llms-locally-using-ollama/">How to Run Open Source LLMs Locally Using Ollama</a></li>
<li><a href="https://klu.ai/glossary/ollama">Ollama: Easily run LLMs locally</a></li>
<li><a href="https://www.theregister.com/2024/03/17/ai_pc_local_llm/">How to run an LLM on your PC, not in the cloud, in less than 10 minutes</a></li>
</ul>


<h3>LM Studio</h3>

<p><img src="https://lmstudio.ai/static/media/demo2.9df5a0e5a9f1d72715e0.gif" alt="" /></p>

<p><a href="https://lmstudio.ai/">LM Studio</a>是一个集成化的，用户友好的，界面漂亮的开源LLM应用程序，它集LLM下载运行和使用于一体，且有着非常好用的图形化的终端。缺点就是对硬件要求较高，且不能当成API来使用，无法与其他工具对接。</p>

<ul>
<li><a href="https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio">Run an LLM Locally with LM Studio</a></li>
<li><a href="https://digitaconnect.com/how-to-locally-run-a-llm-on-your-pc/">How to Locally Run a LLM on Your PC</a></li>
</ul>


<h3>GPT4All</h3>

<p><img src="https://img-blog.csdnimg.cn/img_convert/96470331467440dec2951abcac0dd195.png" alt="" /></p>

<p><a href="https://gpt4all.io/index.html">GPT4All</a>是一个与LM Studio类似的集成化的用户友好的工具。除了方便下载外，它也提供了好用的图形化终端来使用LLM。它除了可以使用下载的LLM以外，也支持API，并且除了正常的Chat以外，还能直接处理文档，也就是把文档当作LLM的输入。它对硬件的要求不像LM Studio那样高，缺点是对Mac似乎不太友好，因为它要求必须是最新版本的MacOS。</p>

<h2>总结</h2>

<p>本文介绍了几种使用起来非常方便的在本地运行LLM的方式，根据工具的特点，如果您使用的是Mac，或者想要与其他工具结合使用，那建议最好使用Ollama，毕竟它是对Mac最为友好的；如果硬件比较好就用LM Studio，否则的话就用GTP4ALL。</p>

<h2>参考资料</h2>

<ul>
<li><a href="https://semaphoreci.com/blog/local-llm">6 Ways For Running A Local LLM (how to use HuggingFace)</a></li>
<li><a href="https://www.infoworld.com/article/3705035/5-easy-ways-to-run-an-llm-locally.html">5 easy ways to run an LLM locally</a></li>
<li><a href="https://python.langchain.com/docs/guides/development/local_llms/">Run LLMs locally</a></li>
<li><a href="https://hackernoon.com/how-to-run-your-own-local-llm-updated-for-2024">How to Run Your Own Local LLM (Updated for 2024)</a></li>
<li><a href="https://kleiber.me/blog/2024/01/07/six-ways-running-llm-locally/">Six Ways of Running Large Language Models (LLMs) Locally (January 2024)</a></li>
</ul>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Alex Hilton</span></span>

      




<time class='entry-date' datetime='2024-05-01T23:04:34+08:00'><span class='date'><span class='date-month'>May</span> <span class='date-day'>1</span><span class='date-suffix'>st</span>, <span class='date-year'>2024</span></span> <span class='time'>11:04 pm</span></time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/deeplearning/'>deeplearning</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  
  
    <!-- JiaThis Button BEGIN -->
<div class="jiathis_style_32x32">
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_tqq"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_renren"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END -->

  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2024/04/23/upgrade-to-targetsdk-34/" title="Previous Post: 实战技巧：Android 14适配从挂号到出院">&laquo; 实战技巧：Android 14适配从挂号到出院</a>
      
      
        <a class="basic-alignment right" href="/blog/2024/05/07/prompt-made-easy/" title="Next Post: 优雅的训服大模型：深入浅出Prompt技巧">优雅的训服大模型：深入浅出Prompt技巧 &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="comments"></div>
    <!-- Duoshuo COMMENT BEGIN -->
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script>
    var clientId = 'bc66a01ef24d14fc282b'
    var clientSecret = 'c7fd5e55db1776204fe201fe20c050b140982884'
    var gitment = new Gitment({
      id: 'toughcoder.net',
      owner: 'alexhilton',
      repo: 'alexhilton.github.io',
      oauth: {
        client_id: clientId,
        client_secret: clientSecret,
      },
    })

    gitment.render('comments')
</script>
<!-- Duoshuo COMMENT END -->

  </section>

</div>

<aside class="sidebar">
  
    <section>
    <div class="
        col-lg-2 col-lg-offset-0
        visible-lg-block
        sidebar-container
        catalog-container">
        <div class="side-catalog">
            <hr class="hidden-sm hidden-xs">
            <h3>
                <a class="catalog-toggle" href="#">CATALOG</a>
            </h3>
            <ul class="catalog-body"></ul>
        </div>
    </div>
</section>
<!-- Back to top and Scroll to bottom -->
<a href="#" class="cd-top"></a>
<a href="#" class="cd-bottom"></a>

  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2024 - Alex Hilton -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  









<script type="text/javascript">
    //async load function 
    function async(u, c) {
        var d = document, t = 'script',
            o = d.createElement(t),
            s = d.getElementsByTagName(t)[0];
        o.src = u;
        if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
        s.parentNode.insertBefore(o, s);
    }

    function generateCatalog (selector) {
        var P = $('article'),a,n,t,l,i,c, id;
        a = P.find('h2,h3,h4,h5,h6');
        var index = 0;
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            id = $(this).prop('id');
            if (!id) {
                var nid = 'catalog-section-' + index;
                $(this).attr('id', nid);
                i = '#' + nid;
            } else {
                i = '#' + id;
            }
            t = $(this).text();
            c = $('<a href="'+i+'" rel="nofollow">'+t+'</a>');
            l = $('<li class="'+n+'_nav"></li>').append(c);
            $(selector).append(l);
            index++;
        });
        return true;
    }

    generateCatalog(".catalog-body");

    // toggle side catalog
    $(".catalog-toggle").click((function(e){
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    /*
     * Doc: https://github.com/davist11/jQuery-One-Page-Nav
     * Fork by Hux to support padding
     */
    async("/javascripts/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });

// Navigation Scripts to Show Header on Scroll-Up
jQuery(document).ready(function($) {
    var MQL = 1170;

    //primary navigation slide-in effect
    if ($(window).width() > MQL) {
        // We do not have the sticky nav bar so, first can be zero
        var headerHeight = 0;
        $('nav').each(function() {
            var h = $(this).outerHeight(true);
            headerHeight += h;
        });
        $('header').each(function() {
            var h = $(this).outerHeight(true);
            headerHeight += h;
        });
        $(window).on('scroll', {
                previousTop: 0
            },
            function() {
                var currentTop = $(window).scrollTop(),
                    $catalog = $('.side-catalog');

                this.previousTop = currentTop;

                //adjust the appearance of side-catalog
                $catalog.show()
                if (currentTop > (headerHeight + 42)) {
                    $catalog.addClass('fixed')
                } else {
                    $catalog.removeClass('fixed')
                }
            });
    }
});
</script>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?3fab3b1bae08e6d4a5e638d9e8c6f40a";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


</body>
</html>
